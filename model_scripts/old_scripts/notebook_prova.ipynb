{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 5, 6}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = set([0,1,2,3])\n",
    "b = set([0,2,5,6])\n",
    "a | b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 86],\n",
       "       dtype=torch.int8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([0,1,2,3,4,5,6,7,8,9,10,11,12, 1110])\n",
    "a.to(torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 21],\n",
       "       dtype=torch.int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to(torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "[10]\n"
     ]
    }
   ],
   "source": [
    "d = {'a':[10]}\n",
    "for k, v in d.items():\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/dghilardi/mention_clustering/mention-clustering/zeshel_processed/dataset.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.stack([torch.tensor([0,1,2]), torch.tensor([3,4,5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['Last', 'year', 'Messi', 'has', 'scored', 'two', 'goals']\n",
    "b = 'Last year Messi      has scored two goals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Last', 'year', 'Messi', '', '', '', '', '', 'has', 'scored', 'two', 'goals']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = tokenizer(a, is_split_into_words=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = tok.word_to_tokens(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Last year ' + tokenizer.pad_token + ' Cristiano Ronaldo el mas grande ' + tokenizer.pad_token + ' scored two goals.'\n",
    "y = ' Last year Cristiano Ronaldo el mas grande scored two goals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_token = tokenizer([s], return_tensors='pt', max_length=15, padding='max_length')\n",
    "y_token = tokenizer([y], return_tensors='pt', max_length=15, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2197,  2095,     0, 13675,  2923, 15668,  8923,  2080,  3449,\n",
      "         16137,  9026,     0,  3195,  2048,  3289,  1012,   102]])\n",
      "tensor([[  101,  2197,  2095, 13675,  2923, 15668,  8923,  2080,  3449, 16137,\n",
      "          9026,  3195,  2048,  3289,   102]])\n"
     ]
    }
   ],
   "source": [
    "print(s_token['input_ids'])\n",
    "print(y_token['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = torch.argwhere(s_token['input_ids'][0]==0)[:2].flatten().numpy()\n",
    "mention_idx = [pad_idx[0], pad_idx[1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_idx = list(set(np.arange(s_token['input_ids'][0].shape[0])) - set(pad_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_token_clean = s_token['input_ids'][0][retain_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13675,  2923, 15668,  8923,  2080,  3449, 16137,  9026])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_token_clean[mention_idx[0]:mention_idx[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_output = model(**s_token)\n",
    "y_output = model(**y_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-10.3219, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_output.last_hidden_state[0][5].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-10.0465, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_output.last_hidden_state[0][4].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = 'Last year in the final match'\n",
    "et = 'Messi'\n",
    "rc = 'has scored two goals.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_len = len(lc)\n",
    "et_len = len(et)\n",
    "rc_len = len(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = lc +' '+et+' '+rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Last year in the final match Messi has scored two goals.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_pos = [lc_len+1,lc_len+1+et_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Messi'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase[et_pos[0]:et_pos[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = tokenizer(frase, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2197, 2095, 1999, 1996, 2345, 2674, 6752, 2072, 2038, 3195, 2048,\n",
       "         3289, 1012,  102]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'char_pos': 'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/dghilardi/mention_clustering/mention-clustering/pytorch_model/notebook_prova.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bchrons-rrubini/home/dghilardi/mention_clustering/mention-clustering/pytorch_model/notebook_prova.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m tok\u001b[39m.\u001b[39;49mchar_to_token([\u001b[39m3\u001b[39;49m,\u001b[39m7\u001b[39;49m])\n",
      "File \u001b[0;32m/home/dghilardi/mention_clustering/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:594\u001b[0m, in \u001b[0;36mBatchEncoding.char_to_token\u001b[0;34m(self, batch_or_char_index, char_index, sequence_index)\u001b[0m\n\u001b[1;32m    592\u001b[0m     batch_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    593\u001b[0m     char_index \u001b[39m=\u001b[39m batch_or_char_index\n\u001b[0;32m--> 594\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_encodings[batch_index]\u001b[39m.\u001b[39;49mchar_to_token(char_index, sequence_index)\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 'char_pos': 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "tok."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
